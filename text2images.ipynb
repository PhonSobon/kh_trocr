{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caba5134",
   "metadata": {},
   "source": [
    "# Generate image dataset for Khmer text recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73057e2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T17:05:54.422659800Z",
     "start_time": "2025-12-10T17:05:54.305114200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "from PIL import features\n",
    "print(features.check(\"raqm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0373e6fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T17:05:56.317676100Z",
     "start_time": "2025-12-10T17:05:54.435658900Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eb10e0",
   "metadata": {},
   "source": [
    "## 1. Load datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42d2d71",
   "metadata": {},
   "source": [
    "### 1.1 Loading text word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699d0e72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T17:06:02.978574Z",
     "start_time": "2025-12-10T17:06:01.153246800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Loaded 2423810 words from combined_cleaned.txt\n",
      "Sample words: ['ព្រះរាជាណាចក្រ', 'កម្ពុជា', 'ជាតិ', 'សាសនា', 'ព្រះមហាក្សត']\n",
      "\n",
      "DataFrame shape: (2423810, 1)\n"
     ]
    }
   ],
   "source": [
    "# 1.1. Loading words data\n",
    "dataset_path = 'all_cleaned_words.txt'\n",
    "\n",
    "# Read all words from the text file\n",
    "with open(dataset_path, 'r', encoding='utf-8') as f:\n",
    "    words = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "print(f\"\\n✓ Loaded {len(words)} words from {dataset_path}\")\n",
    "print(f\"Sample words: {words[:5]}\")\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({'word': words})\n",
    "print(f\"\\nDataFrame shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e3b3e1",
   "metadata": {},
   "source": [
    "## 2: Generate text to images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58798cc9",
   "metadata": {},
   "source": [
    "### 2.1. Import function for generate text to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ef752ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T17:06:08.999979400Z",
     "start_time": "2025-12-10T17:06:08.810051200Z"
    }
   },
   "outputs": [],
   "source": [
    "def gen_khmer_text_image(index, content, data_type, bg, \n",
    "                        font_path, font_size, data_folder, padding=10):\n",
    "    \"\"\"\n",
    "    Generate an image from Khmer text with specified styling parameters\n",
    "    Image size adapts to text content\n",
    "    \n",
    "    Args:\n",
    "        index: Index number for filename\n",
    "        content: The text to render\n",
    "        data_type: 'train', 'valid', or 'test'\n",
    "        bg: Background color (R, G, B, A)\n",
    "        font_path: Path to the font file\n",
    "        font_size: Size of the font\n",
    "        data_folder: Base folder for output\n",
    "        padding: Padding around text (pixels)\n",
    "    \n",
    "    Returns:\n",
    "        Filename of the generated image\n",
    "    \"\"\"\n",
    "    # Load font first to measure text\n",
    "    try:\n",
    "        font = ImageFont.truetype(font_path, font_size)\n",
    "    except:\n",
    "        print(f\"Warning: Could not load font {font_path}, using default\")\n",
    "        font = ImageFont.load_default()\n",
    "    \n",
    "    # Create temporary image to measure text\n",
    "    temp_img = Image.new('RGBA', (1, 1))\n",
    "    temp_draw = ImageDraw.Draw(temp_img)\n",
    "    \n",
    "    # Get text bounding box\n",
    "    bbox = temp_draw.textbbox((0, 0), content, font=font)\n",
    "    text_width = bbox[2] - bbox[0]\n",
    "    text_height = bbox[3] - bbox[1]\n",
    "    \n",
    "    # Calculate image size based on text with padding\n",
    "    img_width = text_width + (padding * 2)\n",
    "    img_height = text_height + (padding * 2)\n",
    "    \n",
    "    # Create actual image with calculated size\n",
    "    image = Image.new('RGBA', (img_width, img_height), bg)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    # Draw text with padding offset\n",
    "    draw.text((padding, padding), content, font=font, fill=(0, 0, 0, 255))\n",
    "    \n",
    "    # Generate filename with 6-digit index\n",
    "    filename = f\"{index:06d}.png\"\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir = os.path.join(data_folder, data_type)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save image\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    image.save(output_path)\n",
    "    \n",
    "    return filename\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbfaf1b",
   "metadata": {},
   "source": [
    "### 2.2. Define Variant values for Function Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846a9213",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T17:06:12.612834600Z",
     "start_time": "2025-12-10T17:06:12.540866800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discovered fonts:\n",
      "  • fonts\\KhmerDigital-Black.ttf\n",
      "  • fonts\\KhmerDigital-Bold.ttf\n",
      "  • fonts\\KhmerDigital-ExtraBold.ttf\n",
      "  • fonts\\KhmerDigital-ExtraLight.ttf\n",
      "  • fonts\\KhmerDigital-Light.ttf\n",
      "  • fonts\\KhmerDigital-Medium.ttf\n",
      "  • fonts\\KhmerDigital-Regular.ttf\n",
      "  • fonts\\KhmerDigital-SemiBold.ttf\n",
      "  • fonts\\KhmerDigital-Thin.ttf\n",
      "  • fonts\\KhmerDigitalMax.ttf\n",
      "  • fonts\\KhmerDigitalNumber.ttf\n",
      "  • fonts\\KhmerDigitalNumberMax.ttf\n",
      "  • fonts\\KhmerMPTC.ttf\n",
      "  • fonts\\KhmerMPTCMoul.otf\n",
      "  • fonts\\KhmerOS_muollight.ttf\n",
      "  • fonts\\KhmerOS_siemreap.ttf\n",
      "\n",
      "✓ 16 fonts\n",
      "✓ 8 font sizes\n",
      "✓ 1 background colors\n"
     ]
    }
   ],
   "source": [
    "fonts_dir = \"fonts\"\n",
    "fonts = []\n",
    "\n",
    "if os.path.exists(fonts_dir):\n",
    "    for filename in os.listdir(fonts_dir):\n",
    "        if filename.endswith(('.ttf', '.otf', '.TTF', '.OTF')):\n",
    "            font_path = os.path.join(fonts_dir, filename)\n",
    "            fonts.append(font_path)\n",
    "    fonts.sort()  # Sort alphabetically for consistency\n",
    "else:\n",
    "    print(f\"Warning: '{fonts_dir}' folder not found!\")\n",
    "    fonts = []\n",
    "\n",
    "if not fonts:\n",
    "    print(\"ERROR: No font files found in 'fonts/' folder!\")\n",
    "    print(\"Please ensure .ttf or .otf font files are in the 'fonts/' directory\")\n",
    "    exit()\n",
    "\n",
    "print(f\"\\nDiscovered fonts:\")\n",
    "for font in fonts:\n",
    "    print(f\"  • {font}\")\n",
    "\n",
    "# Font sizes\n",
    "font_sizes = [12,13,14,15,16]\n",
    "\n",
    "# Background colors\n",
    "bg_colors = [\n",
    "    (255, 255, 255, 255),\n",
    "]\n",
    "\n",
    "print(f\"\\n✓ {len(fonts)} fonts\")\n",
    "print(f\"✓ {len(font_sizes)} font sizes\")\n",
    "print(f\"✓ {len(bg_colors)} background colors\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b5a6b5",
   "metadata": {},
   "source": [
    "### 2.3 Splitting The Dataset: Train, Validation, Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1df9f4bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T17:06:19.783568600Z",
     "start_time": "2025-12-10T17:06:19.348527500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2.3. Splitting the dataset...\n",
      "✓ Train: 1696667 words\n",
      "✓ Validation: 363571 words\n",
      "✓ Test: 363572 words\n"
     ]
    }
   ],
   "source": [
    "# 2.3 Splitting The Dataset: Train, Validation, Test\n",
    "print(\"\\n2.3. Splitting the dataset...\")\n",
    "\n",
    "# Split: 70% train, 15% validation, 15% test\n",
    "train, temp = train_test_split(df, test_size=0.3, random_state=42)\n",
    "valid, test = train_test_split(temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Reset indices for proper numbering\n",
    "train = train.reset_index(drop=True)\n",
    "valid = valid.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)\n",
    "\n",
    "print(f\"✓ Train: {len(train)} words\")\n",
    "print(f\"✓ Validation: {len(valid)} words\")\n",
    "print(f\"✓ Test: {len(test)} words\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2942534d",
   "metadata": {},
   "source": [
    "### 2.4 Generating Text to Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebf17d61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T17:06:23.300821Z",
     "start_time": "2025-12-10T17:06:23.286023200Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2.4 Generating Text to Images\n",
    "# Create base output directory\n",
    "data_folder = \"data_v1\"\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "\n",
    "# Lists to store labels\n",
    "train_labels = []\n",
    "valid_labels = []\n",
    "test_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3142f4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T17:06:42.108271800Z",
     "start_time": "2025-12-10T17:06:27.482664500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "Generating TRAIN images...\n",
      "------------------------------------------------------------\n",
      "100 of 1696667: complete\n",
      "200 of 1696667: complete\n",
      "300 of 1696667: complete\n",
      "400 of 1696667: complete\n",
      "500 of 1696667: complete\n",
      "600 of 1696667: complete\n",
      "700 of 1696667: complete\n",
      "800 of 1696667: complete\n",
      "900 of 1696667: complete\n",
      "1000 of 1696667: complete\n",
      "1100 of 1696667: complete\n",
      "1200 of 1696667: complete\n",
      "1300 of 1696667: complete\n",
      "1400 of 1696667: complete\n",
      "1500 of 1696667: complete\n",
      "1600 of 1696667: complete\n",
      "1700 of 1696667: complete\n",
      "1800 of 1696667: complete\n",
      "1900 of 1696667: complete\n",
      "2000 of 1696667: complete\n",
      "2100 of 1696667: complete\n",
      "2200 of 1696667: complete\n",
      "2300 of 1696667: complete\n",
      "2400 of 1696667: complete\n",
      "2500 of 1696667: complete\n",
      "2600 of 1696667: complete\n",
      "2700 of 1696667: complete\n",
      "2800 of 1696667: complete\n",
      "2900 of 1696667: complete\n",
      "3000 of 1696667: complete\n",
      "3100 of 1696667: complete\n",
      "3200 of 1696667: complete\n",
      "3300 of 1696667: complete\n",
      "3400 of 1696667: complete\n",
      "3500 of 1696667: complete\n",
      "3600 of 1696667: complete\n",
      "3700 of 1696667: complete\n",
      "3800 of 1696667: complete\n",
      "3900 of 1696667: complete\n",
      "4000 of 1696667: complete\n",
      "4100 of 1696667: complete\n",
      "4200 of 1696667: complete\n",
      "4300 of 1696667: complete\n",
      "4400 of 1696667: complete\n",
      "4500 of 1696667: complete\n",
      "4600 of 1696667: complete\n",
      "4700 of 1696667: complete\n",
      "4800 of 1696667: complete\n",
      "4900 of 1696667: complete\n",
      "5000 of 1696667: complete\n",
      "5100 of 1696667: complete\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m bg = random.choice(bg_colors)\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     filename = \u001b[43mgen_khmer_text_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mword\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfont_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfont\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfont_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfont_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_folder\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m     train_labels.append(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[33m'\u001b[39m\u001b[33mword\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mgen_khmer_text_image\u001b[39m\u001b[34m(index, content, data_type, bg, font_path, font_size, data_folder, padding)\u001b[39m\n\u001b[32m     42\u001b[39m draw = ImageDraw.Draw(image)\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Draw text with padding offset\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[43mdraw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfont\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfont\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m255\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# Generate filename with 6-digit index\u001b[39;00m\n\u001b[32m     48\u001b[39m filename = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m06d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.png\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\PIL\\ImageDraw.py:565\u001b[39m, in \u001b[36mImageDraw.text\u001b[39m\u001b[34m(self, xy, text, fill, font, anchor, spacing, align, direction, features, language, stroke_width, stroke_fill, embedded_color, *args, **kwargs)\u001b[39m\n\u001b[32m    562\u001b[39m     draw_text(ink, \u001b[32m0\u001b[39m)\n\u001b[32m    563\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    564\u001b[39m     \u001b[38;5;66;03m# Only draw normal text\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m     \u001b[43mdraw_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mink\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\PIL\\ImageDraw.py:508\u001b[39m, in \u001b[36mImageDraw.text.<locals>.draw_text\u001b[39m\u001b[34m(ink, stroke_width, stroke_offset)\u001b[39m\n\u001b[32m    506\u001b[39m     start.append(math.modf(xy[i])[\u001b[32m0\u001b[39m])\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m508\u001b[39m     mask, offset = \u001b[43mfont\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetmask2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdirection\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdirection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    514\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstroke_width\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstroke_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[43m        \u001b[49m\u001b[43manchor\u001b[49m\u001b[43m=\u001b[49m\u001b[43manchor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    516\u001b[39m \u001b[43m        \u001b[49m\u001b[43mink\u001b[49m\u001b[43m=\u001b[49m\u001b[43mink\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    521\u001b[39m     coord = coord[\u001b[32m0\u001b[39m] + offset[\u001b[32m0\u001b[39m], coord[\u001b[32m1\u001b[39m] + offset[\u001b[32m1\u001b[39m]\n\u001b[32m    522\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\PIL\\ImageFont.py:580\u001b[39m, in \u001b[36mFreeTypeFont.getmask2\u001b[39m\u001b[34m(self, text, mode, direction, features, language, stroke_width, anchor, ink, start, *args, **kwargs)\u001b[39m\n\u001b[32m    577\u001b[39m     im = Image.core.fill(mode, size)\n\u001b[32m    578\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m im\n\u001b[32m--> \u001b[39m\u001b[32m580\u001b[39m offset = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfont\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    581\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfill\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    584\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdirection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    585\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    586\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    587\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstroke_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    588\u001b[39m \u001b[43m    \u001b[49m\u001b[43manchor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    589\u001b[39m \u001b[43m    \u001b[49m\u001b[43mink\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    592\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    593\u001b[39m Image._decompression_bomb_check(size)\n\u001b[32m    594\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m im, offset\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\PIL\\ImageFont.py:568\u001b[39m, in \u001b[36mFreeTypeFont.getmask2.<locals>.fill\u001b[39m\u001b[34m(mode, im_size)\u001b[39m\n\u001b[32m    565\u001b[39m im = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    566\u001b[39m size = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m568\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfill\u001b[39m(mode, im_size):\n\u001b[32m    569\u001b[39m     \u001b[38;5;28;01mnonlocal\u001b[39;00m im, size\n\u001b[32m    571\u001b[39m     size = im_size\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Generating training data to image\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"Generating TRAIN images...\")\n",
    "print(\"-\"*60)\n",
    "i = 1\n",
    "n = len(train)\n",
    "for index, row in train.iterrows():\n",
    "    font_size = random.choice(font_sizes)\n",
    "    font = random.choice(fonts)\n",
    "    bg = random.choice(bg_colors)\n",
    "    \n",
    "    try:\n",
    "        filename = gen_khmer_text_image(\n",
    "            index=index+1, \n",
    "            content=row[\"word\"],\n",
    "            data_type=\"train\", \n",
    "            bg=bg,\n",
    "            font_path=font, \n",
    "            font_size=font_size,\n",
    "            data_folder=data_folder\n",
    "        )\n",
    "        \n",
    "        train_labels.append(f\"{filename}\\t{row['word']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing word '{row['word']}': {e}\")\n",
    "        continue\n",
    "    \n",
    "    if i % 100 == 0 or i == n:\n",
    "        print(f\"{i} of {n}: complete\")\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ddca1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Generating validation data to image\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"Generating VALID images...\")\n",
    "print(\"-\"*60)\n",
    "i = 1\n",
    "n = len(valid)\n",
    "for index, row in valid.iterrows():\n",
    "    font_size = random.choice(font_sizes)\n",
    "    font = random.choice(fonts)\n",
    "    bg = random.choice(bg_colors)\n",
    "    \n",
    "    try:\n",
    "        filename = gen_khmer_text_image(\n",
    "            index=index+1, \n",
    "            content=row[\"word\"],\n",
    "            data_type=\"valid\", \n",
    "            bg=bg,\n",
    "            font_path=font, \n",
    "            font_size=font_size,\n",
    "            data_folder=data_folder\n",
    "        )\n",
    "        \n",
    "        valid_labels.append(f\"{filename}\\t{row['word']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing word '{row['word']}': {e}\")\n",
    "        continue\n",
    "    \n",
    "    if i % 100 == 0 or i == n:\n",
    "        print(f\"{i} of {n}: complete\")\n",
    "    i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf5d2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# Generating testing data to image\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"Generating TEST images...\")\n",
    "print(\"-\"*60)\n",
    "i = 1\n",
    "n = len(test)\n",
    "for index, row in test.iterrows():\n",
    "    font_size = random.choice(font_sizes)\n",
    "    font = random.choice(fonts)\n",
    "    bg = random.choice(bg_colors)\n",
    "    \n",
    "    try:\n",
    "        filename = gen_khmer_text_image(\n",
    "            index=index+1, \n",
    "            content=row[\"word\"],\n",
    "            data_type=\"test\", \n",
    "            bg=bg,\n",
    "            font_path=font, \n",
    "            font_size=font_size,\n",
    "            data_folder=data_folder\n",
    "        )\n",
    "        \n",
    "        test_labels.append(f\"{filename}\\t{row['word']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing word '{row['word']}': {e}\")\n",
    "        continue\n",
    "    \n",
    "    if i % 100 == 0 or i == n:\n",
    "        print(f\"{i} of {n}: complete\")\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6da38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "Saving label files...\n",
      "------------------------------------------------------------\n",
      "✓ Saved train.txt (7475 entries)\n",
      "✓ Saved valid.txt (0 entries)\n",
      "✓ Saved test.txt (0 entries)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"Saving label files...\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# Save train.txt\n",
    "with open(os.path.join(data_folder, 'train.txt'), 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(train_labels))\n",
    "print(f\"✓ Saved train.txt ({len(train_labels)} entries)\")\n",
    "\n",
    "# Save valid.txt\n",
    "with open(os.path.join(data_folder, 'valid.txt'), 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(valid_labels))\n",
    "print(f\"✓ Saved valid.txt ({len(valid_labels)} entries)\")\n",
    "\n",
    "# Save test.txt\n",
    "with open(os.path.join(data_folder, 'test.txt'), 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(test_labels))\n",
    "print(f\"✓ Saved test.txt ({len(test_labels)} entries)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3564de26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GENERATION COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Train images: {len(train_labels)} → data_v1/train/\")\n",
    "print(f\"Valid images: {len(valid_labels)} → data_v1/valid/\")\n",
    "print(f\"Test images: {len(test_labels)} → data_v1/test/\")\n",
    "print(f\"\\nLabel files:\")\n",
    "print(f\"  • data_v1/train.txt\")\n",
    "print(f\"  • data_v1/valid.txt\")\n",
    "print(f\"  • data_v1/test.txt\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7117d47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_filename = \"data_v1\"\n",
    "shutil.make_archive(zip_filename, 'zip', data_folder)\n",
    "\n",
    "print(f\"✓ Created {zip_filename}.zip\")\n",
    "print(f\"✓ File size: {os.path.getsize(zip_filename + '.zip') / (1024*1024):.2f} MB\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DOWNLOAD READY!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Download file: {zip_filename}.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b6ae79",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    display(FileLink(f\"{zip_filename}.zip\"))\n",
    "    print(\"\\nClick the link above to download\")\n",
    "except:\n",
    "    print(f\"\\nTo download, locate the file: {zip_filename}.zip\")\n",
    "    print(\"In Jupyter: Right-click the file in the file browser and select 'Download'\")\n",
    "    print(\"In Colab: Find the file in the Files panel on the left and click the download icon\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
